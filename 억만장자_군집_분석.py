# -*- coding: utf-8 -*-
"""억만장자 군집 분석.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kliy5Cfrcn1ro30qFp8X-MggOTRGlhIl
"""

import kagglehub
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
!apt-get -qq -y install fonts-nanum > /dev/null

fe = fm.FontEntry(
    fname=r'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',
    name='NanumGothic')
fm.fontManager.ttflist.insert(0, fe)
plt.rcParams.update({'font.size': 12, 'font.family': 'NanumGothic'})

"""## 데이터 불러오기"""

# Download latest version
path = kagglehub.dataset_download("nelgiriyewithana/billionaires-statistics-dataset")

print("Path to dataset files:", path)

df = pd.read_csv(path +"/Billionaires Statistics Dataset.csv")

print(df.shape)

df.head()

df.info()

df.describe()

df.isnull().sum()

"""## 데이터 전처리

결측치가 많고 불필요한 컬럼 제거
"""

df.drop(['personName', 'firstName', 'lastName', 'organization','title', 'birthDate', 'birthMonth',
         'date','residenceStateRegion', 'cpi_change_country','state','countryOfCitizenship',
         'gross_primary_education_enrollment_country', 'birthDay', 'birthYear'], axis=1,inplace=True)

"""형 변환"""

df['gdp_country'] = df['gdp_country'].str.replace('$', '').str.replace(',', '').str.strip().astype(float)
df['selfMade'] = df['selfMade'].astype(str)

"""결측치 대체"""

# Age 중앙값으로 대체
df['age'] = df['age'].fillna(df['age'].median())

# 같은 국가의 최빈값 or 해당 컬럼의 중앙값으로 대체
df['city'] = df.groupby('country')['city'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else pd.NA))
df['gross_tertiary_education_enrollment'] = df.groupby('country')['gross_tertiary_education_enrollment'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else df['gross_tertiary_education_enrollment'].median()))
df['cpi_country'] = df.groupby('country')['cpi_country'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else df['cpi_country'].median()))
df['gdp_country'] = df.groupby('country')['gdp_country'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else df['gdp_country'].median()))
df['life_expectancy_country'] = df.groupby('country')['life_expectancy_country'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else df['life_expectancy_country'].median()))
df['tax_revenue_country_country'] = df.groupby('country')['tax_revenue_country_country'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else df['tax_revenue_country_country'].median()))
df['total_tax_rate_country'] = df.groupby('country')['total_tax_rate_country'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else df['total_tax_rate_country'].median()))
df['population_country'] = df.groupby('country')['population_country'].transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else df['population_country'].median()))

df = df.dropna(subset=['country', 'city'])
df.isnull().sum()

"""country는 있지만 latitude, longitude가 없는 데이터 존재"""

missing_lat_counts = df[df['latitude_country'].isna()]['country'].value_counts()
print("국가별 latitude 결측치 개수:")
print(missing_lat_counts.sum)

# Hong Kong 위도/경도 채우기
df.loc[df['country'] == 'Hong Kong', 'latitude_country'] = 22.3193
df.loc[df['country'] == 'Hong Kong', 'longitude_country'] = 114.1694

# Taiwan 위도/경도 채우기
df.loc[df['country'] == 'Taiwan', 'latitude_country'] = 23.5937
df.loc[df['country'] == 'Taiwan', 'longitude_country'] = 121.0254

#나머지 데이터는 제거
df = df.dropna()

df.isnull().sum()

df.shape

"""## EDA"""

columns_translation = {
    'rank': '순위',
    'finalWorth': '최종 자산',
    'age': '나이',
    'cpi_country': '국가 CPI',
    'gdp_country': '국가 GDP',
    'gross_tertiary_education_enrollment': '고등 교육 등록률',
    'life_expectancy_country': '국가 기대 수명',
    'tax_revenue_country_country': '세수 비율',
    'total_tax_rate_country': '전체 세율',
    'population_country': '국가 인구',
    'latitude_country': '국가 위도',
    'longitude_country': '국가 경도'
}

# 수치형 열 선택 및 이름 번역
numeric_cols = list(columns_translation.keys())
translated_cols = [columns_translation[col] for col in numeric_cols]

# 상관계수 계산
correlation_matrix = df[numeric_cols].corr()

# 열 이름 번역 반영
correlation_matrix.columns = translated_cols
correlation_matrix.index = translated_cols

# 히트맵 그리기
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap="coolwarm", cbar=True)
plt.title("변수 간 상관관계 히트맵")
plt.show()

selfMade_counts = df['selfMade'].value_counts()
colors = sns.color_palette('Pastel1')

explode = (0.03, 0.03)

plt.figure(figsize=(5,5))
plt.pie(selfMade_counts, labels = selfMade_counts.index, autopct='%1.1f%%,', colors = colors, explode=explode)
plt.title('자수성가 여부', pad=20, size=14)
plt.show()

# 데이터
selfMade_counts = df['gender'].value_counts()
colors = sns.color_palette('Set2')

# 원형 차트 그리기
plt.figure(figsize=(5,5))
wedges, texts, autotexts = plt.pie(
    selfMade_counts,
    labels=selfMade_counts.index,
    autopct='%1.1f%%',
    colors=colors,
    startangle=25,  # 차트 시작 각도 조정
    textprops={'fontsize': 12, 'weight': 'bold'},  # 텍스트 스타일 조정
    wedgeprops={'edgecolor': 'white', 'linewidth': 2},  # 테두리 추가
)

# 제목 및 스타일 설정
plt.title('억만장자 성별 비율', pad=20, size=16, weight='bold')

# 레이아웃 및 출력
plt.tight_layout()
plt.show()

country_counts = df['country'].value_counts()
top_5 = country_counts.head(6)
others = pd.Series({'Others': country_counts[5:].sum()})
combined_counts = pd.concat([top_5, others])

colors = sns.color_palette('tab10', len(combined_counts))

plt.figure(figsize=(8,8))
plt.pie(combined_counts, labels=combined_counts.index, autopct='%1.1f%%,', colors = colors)
plt.title('국가별 분포', pad=20, size=14)
plt.show()

import folium
from folium.plugins import MarkerCluster

m = folium.Map(location=[0, 0], zoom_start=2)

marker_cluster = MarkerCluster()

for index, row in df.iterrows():
    if not pd.isna(row['latitude_country']) and not pd.isna(row['longitude_country']):
        folium.Marker([row['latitude_country'], row['longitude_country']]).add_to(marker_cluster)

marker_cluster.add_to(m)

m

plt.figure(figsize=(12, 8))
sns.histplot(data=df, x='age', bins=range(20, 101, 10), kde=True,binwidth=3)
plt.xlabel('나이', size=12)
plt.ylabel('인원 수', size=12)
plt.title('나이 분포', pad=20, size=14)
plt.xticks(range(20, 101, 5))
plt.tight_layout()
plt.show()

category_count = df['category'].value_counts()
colors = sns.color_palette('muted')

plt.figure(figsize=(13, 6))
plt.bar(category_count.index, category_count.values, color=colors)
plt.xticks(rotation=45, ha='right')
plt.title('산업분야 분포', pad=20, size=14)
plt.ylabel('인원 수', size=12)
plt.tight_layout()
plt.show()

# 상위 10개 source 추출
source_counts = df['source'].value_counts().head(10).sort_values(ascending=True)

plt.figure(figsize=(14, 8))

# 색상 팔레트 설정 (여러 옵션 중 'husl' 사용)
colors = sns.color_palette('husl', n_colors=len(source_counts))

# 가로 막대 그래프 생성
bars = plt.barh(range(len(source_counts)), source_counts.values,
                color=colors,
                alpha=0.8,
                height=0.6)

# y축 레이블 설정
plt.yticks(range(len(source_counts)), source_counts.index)

# 그래프 꾸미기
plt.title('자산 출처 분포', pad=20, size=14)
plt.xlabel('인원 수', size=12)

plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)

# 격자 추가
plt.grid(True, axis='x', linestyle='--', alpha=0.3)

# 값 레이블 추가
for i, v in enumerate(source_counts.values):
    plt.text(v, i, f' {v:,}', va='center', fontsize=11)


# 여백 조정
plt.tight_layout()

plt.show()

# 상위 6개 산업 추출
category = df['category'].value_counts().head(6).index
top6 = df[df['category'].isin(category)]

# 시각화
plt.figure(figsize=(8, 8))
c_plot = sns.countplot(
    data=top6,
    x='category',
    hue='selfMade',
    hue_order=['True', 'False'],  # 명시적으로 지정
    palette='Set2',
    order=category
)

# 축과 제목 설정
plt.xlabel('산업분야', fontsize=12)
plt.ylabel('인원 수', fontsize=12)
plt.title('산업분야 별 자수성가 분석', fontsize=14)
c_plot.set_xticklabels(c_plot.get_xticklabels(), rotation=45, ha='right')

# 막대 위에 라벨 표시
for container in c_plot.containers:
    c_plot.bar_label(container, fmt='%d', label_type='edge')

# 레이아웃 정리
plt.tight_layout()
plt.show()

categories = df['category'].value_counts().head(6).index
top6 = df[df['category'].isin(categories)]

plt.figure(figsize=(8, 7))
c_plot = sns.countplot(data=top6,
                     x='category',
                     hue='gender',
                     order=categories)

plt.xlabel('산업 분야')
plt.ylabel('인원 수')
plt.title('산업 별 성별 분석')
c_plot.set_xticklabels(c_plot.get_xticklabels(), rotation=45)

for i in c_plot.containers:
   c_plot.bar_label(i,)

plt.tight_layout()
plt.show()

# 성별로 데이터 분리
male_df = df[df['gender'] == 'M']
female_df = df[df['gender'] == 'F']

# 각 성별의 상위 5개 카테고리 추출
male_top5 = male_df['category'].value_counts().head(5)
female_top5 = female_df['category'].value_counts().head(5)

# 그래프 생성
plt.figure(figsize=(14, 13))

# 남성 그래프 (위)
plt.subplot(2, 1, 1)
male_plot = sns.barplot(x=male_top5.values, y=male_top5.index, color='skyblue')
plt.title('남성 상위 5개 산업')
plt.xlabel('인원 수')
plt.ylabel('산업 분야')

# 막대에 값 표시
for i, v in enumerate(male_top5.values):
    male_plot.text(v, i, f' {v:,}', va='center')

# 여성 그래프 (아래)
plt.subplot(2, 1, 2)
female_plot = sns.barplot(x=female_top5.values, y=female_top5.index, color='pink')
plt.title('여성 상위 5개 산업')
plt.xlabel('인원 수')
plt.ylabel('산업 분야')

# 막대에 값 표시
for i, v in enumerate(female_top5.values):
    female_plot.text(v, i, f' {v:,}', va='center')

plt.tight_layout()
plt.show()

# 상위 6개 국가 추출
countries = df['country'].value_counts().head(6).index
top6 = df[df['country'].isin(countries)]

# 시각화
plt.figure(figsize=(8, 6))
c_plot = sns.countplot(
    data=top6,
    x='country',
    hue='selfMade',
    hue_order=['True', 'False'],  # 명시적으로 지정
    palette='Set2',
    order=countries  # 변수 재사용
)

# 축과 제목 설정
plt.xlabel('국가', fontsize=12)
plt.ylabel('인원 수', fontsize=12)
plt.title('국가 별 자수성가 분석', fontsize=14)

# 막대 위에 라벨 표시
for container in c_plot.containers:
    c_plot.bar_label(container, fmt='%d', label_type='edge')

# 레이아웃 정리
plt.tight_layout()
plt.show()

countries = df['country'].value_counts().head(6).index
top6 = df[df['country'].isin(countries)]
grouped_data = pd.crosstab(top6['country'], top6['gender'])
grouped_data = grouped_data.reindex(countries)  # 국가 순서 재정렬

grouped_data = grouped_data[['M', 'F']]

# 크기를 지정하고 서브플롯 생성
fig, ax = plt.subplots(figsize=(8, 8))

# 누적 막대 그래프 생성
colors = ['skyblue', 'pink']  # 파란색(남성), 빨간색(여성)
grouped_data.plot(
    kind='bar',
    stacked=True,
    color=colors,
    ax=ax  # 기존 ax에 플롯 그리기
)

# 그래프 꾸미기
ax.set_title('국가별 성별 분석', pad=20, size=16)
ax.set_xlabel('국가', size=14)
ax.set_ylabel('인원 수', size=14)

ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')

# 각 부분에 값 표시
for c in ax.containers:
    ax.bar_label(c, label_type='center')

# 그래프 레이아웃 조정 및 표시
fig.tight_layout()
plt.show()

"""# K-Means clustering 군집"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_samples, silhouette_score
import matplotlib.cm as cm

# 수치형 데이터 선택
numeric_columns = ['age', 'cpi_country', 'gdp_country',
                  'gross_tertiary_education_enrollment', 'life_expectancy_country',
                  'tax_revenue_country_country', 'total_tax_rate_country',
                  'population_country']

# 필요한 컬럼만 선택
X = df[numeric_columns].copy()

# 스케일링
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 엘보우 메소드를 위한 inertia 계산
inertias = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_scaled)
    inertias.append(kmeans.inertia_)

# 엘보우 그래프 그리기
plt.figure(figsize=(10, 6))
plt.plot(range(1, 11), inertias, marker='o')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.grid(True)
plt.show()

# 클러스터 개수 설정
k_values = [4, 5, 6, 7]

# 실루엣 분석을 위한 그래프
fig1 = plt.figure(figsize=(16, 12))

for idx, k in enumerate(k_values):
    kmeans = KMeans(n_clusters=k, random_state=42)
    clusters = kmeans.fit_predict(X_scaled)

    silhouette_avg = silhouette_score(X_scaled, clusters)
    sample_silhouette_values = silhouette_samples(X_scaled, clusters)

    plt.subplot(2, 2, idx+1)
    y_lower = 10

    for i in range(k):
        ith_cluster_silhouette_values = sample_silhouette_values[clusters == i]
        ith_cluster_silhouette_values.sort()

        size_cluster_i = ith_cluster_silhouette_values.shape[0]
        y_upper = y_lower + size_cluster_i

        color = cm.nipy_spectral(float(i) / k)
        plt.fill_betweenx(np.arange(y_lower, y_upper),
                         0, ith_cluster_silhouette_values,
                         facecolor=color, edgecolor=color, alpha=0.7)

        plt.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
        y_lower = y_upper + 10

    plt.title(f'Number of Clusters: {k}\nSilhouette Score: {silhouette_avg:.3f}',
              fontsize=12)
    plt.xlabel('Silhouette coefficient', fontsize=10)
    plt.ylabel('Cluster label', fontsize=10)
    plt.axvline(x=silhouette_avg, color="red", linestyle="--")
    plt.yticks([])
    plt.xlim([-0.1, 1])

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

# 클러스터 분포를 위한 그래프

# PCA 변환
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

fig2 = plt.figure(figsize=(13, 10))

for idx, k in enumerate(k_values):
    kmeans = KMeans(n_clusters=k, random_state=42)
    clusters = kmeans.fit_predict(X_scaled)

    plt.subplot(2, 2, idx+1)
    plt.grid(True, linestyle='--', alpha=0.7)

    colors = cm.Set1(np.linspace(0, 1, k))

    for i in range(k):
        mask = clusters == i
        plt.scatter(X_pca[mask, 0], X_pca[mask, 1],
                   c=[colors[i]], edgecolor='black',
                   s=100, label=f'Cluster {i}')

    plt.title(f'Cluster Distribution (k={k})', fontsize=12)
    plt.legend(loc='best', fontsize=8)

    plt.xlim([X_pca[:, 0].min() - 0.5, X_pca[:, 0].max() + 0.5])
    plt.ylim([X_pca[:, 1].min() - 0.5, X_pca[:, 1].max() + 0.5])

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

# 클러스터 개수 설정
k_values = [5, 6]

# 실루엣 분석을 위한 그래프
fig1 = plt.figure(figsize=(8, 10))

for idx, k in enumerate(k_values):
    kmeans = KMeans(n_clusters=k, random_state=42)
    clusters = kmeans.fit_predict(X_scaled)

    silhouette_avg = silhouette_score(X_scaled, clusters)
    sample_silhouette_values = silhouette_samples(X_scaled, clusters)

    # 위아래로 그리기 위해 2x1 설정
    plt.subplot(2, 1, idx+1)
    y_lower = 10

    for i in range(k):
        ith_cluster_silhouette_values = sample_silhouette_values[clusters == i]
        ith_cluster_silhouette_values.sort()

        size_cluster_i = ith_cluster_silhouette_values.shape[0]
        y_upper = y_lower + size_cluster_i

        color = cm.nipy_spectral(float(i) / k)
        plt.fill_betweenx(np.arange(y_lower, y_upper),
                         0, ith_cluster_silhouette_values,
                         facecolor=color, edgecolor=color, alpha=0.7)

        plt.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
        y_lower = y_upper + 10

    plt.title(f'Number of Clusters: {k}\nSilhouette Score: {silhouette_avg:.3f}',
              fontsize=12)
    plt.xlabel('Silhouette coefficient', fontsize=10)
    plt.ylabel('Cluster label', fontsize=10)
    plt.axvline(x=silhouette_avg, color="red", linestyle="--")
    plt.yticks([])
    plt.xlim([-0.1, 1])

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

# 클러스터 분포를 위한 그래프

# PCA 변환
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

fig2 = plt.figure(figsize=(10, 12))

for idx, k in enumerate(k_values):
    kmeans = KMeans(n_clusters=k, random_state=42)
    clusters = kmeans.fit_predict(X_scaled)

    # 위아래로 그리기 위해 2x1 설정
    plt.subplot(2, 1, idx+1)
    plt.grid(True, linestyle='--', alpha=0.7)

    colors = cm.Set1(np.linspace(0, 1, k))

    for i in range(k):
        mask = clusters == i
        plt.scatter(X_pca[mask, 0], X_pca[mask, 1],
                   c=[colors[i]], edgecolor='black',
                   s=100, label=f'Cluster {i}')

    plt.title(f'Cluster Distribution (k={k})', fontsize=12)
    plt.legend(loc='best', fontsize=8)

    plt.xlim([X_pca[:, 0].min() - 0.5, X_pca[:, 0].max() + 0.5])
    plt.ylim([X_pca[:, 1].min() - 0.5, X_pca[:, 1].max() + 0.5])

plt.tight_layout(rect=[0, 0.03, 1, 0.95])
plt.show()

"""## 군집 결과 분석"""

# 실제 사용된 컬럼들
used_columns = [
    'age',
    'cpi_country',
    'gdp_country',
    'gross_tertiary_education_enrollment',
    'life_expectancy_country',
    'tax_revenue_country_country',
    'total_tax_rate_country',
    'population_country'
]

# 번역된 열 이름
used_translated_cols = [columns_translation[col] for col in used_columns]

# 클러스터 5로 군집
kmeans = KMeans(n_clusters=5, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# 클러스터별 평균 계산 및 시각화
plt.figure(figsize=(12, 6))
cluster_means = pd.DataFrame()

for i in range(5):
    mask = clusters == i
    cluster_means[f'클러스터 {i}'] = X_scaled[mask].mean(axis=0)

# 번역된 열 이름 적용
cluster_means.index = used_translated_cols

# 히트맵으로 표현
sns.heatmap(cluster_means, cmap='RdYlBu', center=0, annot=True, fmt='.2f')
plt.title('클러스터 특성 히트맵')
plt.tight_layout()
plt.show()

# 각 클러스터 별 크기 및 비율 계산
def calculate_cluster_stats(clusters, df):
    cluster_stats = []

    for i in range(5):
        cluster_mask = clusters == i
        stats = {
            'Cluster': i,
            'Size': cluster_mask.sum(),
            'Percentage': cluster_mask.sum() / len(clusters) * 100
        }
        cluster_stats.append(stats)

    return pd.DataFrame(cluster_stats)

def print_cluster_summary(clusters, df, stats_df):
    print("\n=== 클러스터별 기본 통계 ===")
    for i in range(5):
        cluster_data = df[clusters == i]
        avg_age = cluster_data['age'].mean()

        print(f"\n[클러스터 {i}]")
        print(f"크기: {stats_df.loc[i, 'Size']:.0f} ({stats_df.loc[i, 'Percentage']:.1f}%)")
        print(f"평균 나이: {avg_age:.1f}세")

        print("\n주요 국가 분포:")
        country_dist = cluster_data['country'].value_counts().head(5)
        for country, count in country_dist.items():
            print(f"{country}: {count}명 ({count/len(cluster_data)*100:.1f}%)")

        print("\n주요 산업 분포:")
        industry_dist = cluster_data['category'].value_counts().head(5)
        for ind, count in industry_dist.items():
            print(f"{ind}: {count}명 ({count/len(cluster_data)*100:.1f}%)")

        print("\n주요 부의 원천:")
        source_dist = cluster_data['source'].value_counts().head(5)
        for source, count in source_dist.items():
            print(f"{source}: {count}명 ({count/len(cluster_data)*100:.1f}%)")

# 통계 계산 및 출력
stats_df = calculate_cluster_stats(clusters, df)
print_cluster_summary(clusters, df, stats_df)